{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "from ml_metrics import quadratic_weighted_kappa\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# array declarations\n",
    "sw=[]\n",
    "s_data = []\n",
    "s_labels = []\n",
    "t_data = []\n",
    "t_labels = []\n",
    "#stopwords tweak - more overhead\n",
    "stop_words = ['http','www','img','border','0','1','2','3','4','5','6','7','8','9']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for stw in stop_words:\n",
    "    sw.append(\"q\"+stw)\n",
    "    sw.append(\"z\"+stw)\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "train = pd.read_csv(\"../raw_train.csv\").fillna(\"\")\n",
    "test  = pd.read_csv(\"../raw_test.csv\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove html, remove non text or numeric, make query and title unique features for counts using prefix (accounted for in stopwords tweak)\n",
    "stemmer = PorterStemmer()\n",
    "## Stemming functionality\n",
    "class stemmerUtility(object):\n",
    "    \"\"\"Stemming functionality\"\"\"\n",
    "    @staticmethod\n",
    "    def stemPorter(review_text):\n",
    "        porter = PorterStemmer()\n",
    "        preprocessed_docs = []\n",
    "        for doc in review_text:\n",
    "            final_doc = []\n",
    "            for word in doc:\n",
    "                final_doc.append(porter.stem(word))\n",
    "                #final_doc.append(wordnet.lemmatize(word)) #note that lemmatize() can also takes part of speech as an argument!\n",
    "            preprocessed_docs.append(final_doc)\n",
    "        return preprocessed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:189: UserWarning: \"http://i104.photobucket.com/albums/m175/champions_on_display/wincraft2013/januaryb/65497012.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "C:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:189: UserWarning: \"http://i104.photobucket.com/albums/m175/champions_on_display/wincraft2013/januaryb/65516012.jpg\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n",
      "C:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:189: UserWarning: \"http://i104.photobucket.com/albums/m175/champions_on_display/wincraft2013/januaryb/6552101\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  '\"%s\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client to get the document behind the URL, and feed that document to Beautiful Soup.' % markup)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train.id)):\n",
    "    s=(\" \").join([\"q\"+ z for z in BeautifulSoup(train[\"query\"][i]).get_text(\" \").split(\" \")]) + \" \" + (\" \").join([\"z\"+ z for z in BeautifulSoup(train.product_title[i]).get_text(\" \").split(\" \")]) + \" \" + BeautifulSoup(train.product_description[i]).get_text(\" \")\n",
    "    s=re.sub(\"[^a-zA-Z0-9]\",\" \", s)\n",
    "    s= (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n",
    "    s_data.append(s)\n",
    "    s_labels.append(str(train[\"median_relevance\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(test.id)):\n",
    "    s=(\" \").join([\"q\"+ z for z in BeautifulSoup(test[\"query\"][i]).get_text().split(\" \")]) + \" \" + (\" \").join([\"z\"+ z for z in BeautifulSoup(test.product_title[i]).get_text().split(\" \")]) + \" \" + BeautifulSoup(test.product_description[i]).get_text()\n",
    "    s=re.sub(\"[^a-zA-Z0-9]\",\" \", s)\n",
    "    s= (\" \").join([stemmer.stem(z) for z in s.split(\" \")])\n",
    "    t_data.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#create sklearn pipeline, fit all, and predit test data\n",
    "clf = Pipeline([\n",
    "        ('v',TfidfVectorizer(min_df=5, max_df=500, max_features=None, strip_accents='unicode', analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(1, 2), use_idf=True, smooth_idf=True, sublinear_tf=True, stop_words = 'english')), \n",
    "        ('svd', TruncatedSVD(n_components=200, algorithm='randomized', n_iter=5, random_state=None, tol=0.0)), \n",
    "        ('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), \n",
    "        #('estimator',LogisticRegressionCV(class_weight='auto'))\n",
    "        ('svm', SVC(C=10.0, kernel='rbf', degree=3, gamma=0.0, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, random_state=None))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight='auto', cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l2', refit=True,\n",
       "           scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegressionCV(class_weight='auto').fit(x,np.array(s_labels,dtype=np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross validation score: 0.5882\n",
      "All Cross Validation Scores: [ 0.57564718  0.58954492  0.58617091  0.58390753  0.60560589]\n",
      "Training time: 106.7 seconds\n"
     ]
    }
   ],
   "source": [
    "cross_val_start = time.time()\n",
    "if __name__ == \"__main__\":\n",
    "    kappa_scorer = metrics.make_scorer(\n",
    "        quadratic_weighted_kappa, \n",
    "        greater_is_better = True\n",
    "    )\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        estimator = clf,\n",
    "        X = s_data,\n",
    "        y = np.array(s_labels,dtype=np.int32),\n",
    "        scoring = kappa_scorer,\n",
    "        cv = StratifiedKFold(s_labels,5,random_state=np.random.randint(1)),\n",
    "        n_jobs = -1\n",
    "    )\n",
    "print(\"Average cross validation score: %0.4f\" % scores.mean())\n",
    "print(\"All Cross Validation Scores: %s\" % scores)\n",
    "print(\"Training time: %0.1f seconds\" % (time.time() - cross_val_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10158"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.fit(s_data, s_labels)\n",
    "t_labels = clf.predict(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output results for submission\n",
    "with open(\"submission.csv\",\"w\") as f:\n",
    "    f.write(\"id,prediction\\n\")\n",
    "    for i in range(len(t_labels)):\n",
    "        f.write(str(test.id[i])+\",\"+str(t_labels[i])+\"\\n\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
