{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cross_validation import cross_val_score, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from ml_metrics import quadratic_weighted_kappa\n",
    "import time\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../raw_train_test.csv\")\n",
    "data.loc[:,'text'] = data.apply(\n",
    "    lambda x: \"%s %s\" % (x['query'], x['product_title']),axis = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tokenization via TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tokenize all of the data (train AND test) in order to be aware of all the terms in both sets. Then, we need to divide this tokenized data into train and test. In order to do this, we need to know the row indices of train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stemmer = nltk.PorterStemmer()\n",
    "    return [stemmer.stem(t.lower()) for t in tokens]\n",
    "\n",
    "tokenization_pipeline = Pipeline(steps = [\n",
    "    ('tfidf',TfidfVectorizer(tokenizer = tokenize, stop_words = 'english'))\n",
    "])\n",
    "\n",
    "train_test_split_idx = data[data.dataset == 'train'].shape[0]\n",
    "X = tokenization_pipeline.fit_transform(data['text'])\n",
    "X_train = X[:train_test_split_idx,:] \n",
    "y_train = data.loc[:train_test_split_idx-1,'median_relevance']\n",
    "\n",
    "test_set_ids = np.array(data.loc[train_test_split_idx:,'id'])\n",
    "X_test =  X[train_test_split_idx:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross validation score: 0.5975\n",
      "All Cross Validation Scores: [ 0.61439355  0.54867142  0.61158444  0.62091436  0.56721934  0.6179734\n",
      "  0.6106239   0.56852321  0.60003877  0.61456973]\n",
      "Training time: 223.2 seconds\n"
     ]
    }
   ],
   "source": [
    "training_start = time.time()\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "    kappa_scorer = metrics.make_scorer(\n",
    "        quadratic_weighted_kappa, \n",
    "        greater_is_better = True\n",
    "    )\n",
    "    \n",
    "    prediction_pipeline = Pipeline(steps = [\n",
    "        ('PCA',TruncatedSVD(n_components=200)),\n",
    "        ('scaler',StandardScaler()),\n",
    "        ('classifier',SVC(C=10,kernel='rbf'))\n",
    "    ])\n",
    "    \n",
    "    model = prediction_pipeline.fit(X_train,y_train)\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        estimator = prediction_pipeline,\n",
    "        X = X_train,\n",
    "        y = y_train,\n",
    "        scoring = kappa_scorer,\n",
    "        cv = StratifiedKFold(y = y_train,n_folds=10),\n",
    "        n_jobs = -1\n",
    "    )\n",
    "print(\"Average cross validation score: %0.4f\" % scores.mean())\n",
    "print(\"All Cross Validation Scores: %s\" % scores)\n",
    "print(\"Training time: %0.1f seconds\" % (time.time() - training_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_X = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\IPython\\kernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from IPython.kernel.zmq import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "data_train = data[data.dataset == 'train']\n",
    "data_train['predicted'] = predicted_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train = data_train[['id','query','product_title','median_relevance','predicted']]\n",
    "data_train.to_csv('../04_svm_actual_vs_predicted.csv',index = False,float_format = \"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time: 35.6 seconds\n"
     ]
    }
   ],
   "source": [
    "prediction_start = time.time()\n",
    "results = pd.DataFrame({\n",
    "'id': test_set_ids,\n",
    "'prediction': model.predict(X_test)\n",
    "})\n",
    "print(\"Prediction time: %0.1f seconds\" % (time.time() - prediction_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results.to_csv('../submissions/04_svm.csv',index=False, float_format = \"%d\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
